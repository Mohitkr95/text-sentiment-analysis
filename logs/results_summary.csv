best_model,best_score,all_scores,cv_results,test_metrics,feature_count,training_samples,test_samples
hard_voting,0.7820512820512822,"{'logistic_regression': 0.7721518987341772, 'random_forest': 0.7382550335570469, 'svm': 0.7515923566878983, 'multinomial_nb': 0.7594936708860761, 'knn': 0.5375, 'balanced_rf': 0.7741935483870969, 'balanced_bagging': 0.7183098591549296, 'hard_voting': 0.7820512820512822, 'soft_voting': 0.7435897435897436}","{'mean_f1': 0.8201499188549233, 'std_f1': 0.022182907883311495, 'cv_scores': [0.8181818181818183, 0.7916666666666667, 0.8021390374331552, 0.8529411764705882, 0.835820895522388]}","{'accuracy': 0.815, 'precision': 0.8157894736842105, 'recall': 0.815, 'f1_score': 0.8148843026891808, 'f1_macro': 0.8148843026891808, 'f1_micro': 0.815}",677,640,200
